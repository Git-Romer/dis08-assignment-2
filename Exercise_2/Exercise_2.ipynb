{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bit604ea35cef5f47b299242b69d90df170",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook contains all solutions from the Exercise 2\n",
    "\n",
    "## Task 1\n",
    "\n",
    "### Nr. 1.1\n",
    "\n",
    "- Write a Python program `csv2json` to convert a given CSV file into a JSON file. This conversion should be generic as possible and able to convert different types of CSV files. For the beginning try to make it work with the [`lotr_clean.csv`](lotr_clean.csv) file I uploaded to GitHub.  \n",
    "\n",
    "For the first part of this task we only concentrated on making our program work with the [`lotr_clean.csv`](lotr_clean.csv). For this we first read the file as usual.  \n",
    "To make the writing process easier later on we define our \"base\" already in the first part. This base contains (entered by hand) all column names and their corresponding fields.  \n",
    "This is repeated for all lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import csv\n",
    "import json\n",
    "# Opening the csv File\n",
    "with open(\"./lotr_clean.csv\", \"r\") as csvFile:\n",
    "    reader = csv.reader(csvFile, delimiter=\";\")\n",
    "    # Ignoring first line containing column names\n",
    "    next(reader)\n",
    "    # Creating base\n",
    "    data = {\"LOTR\": []}\n",
    "    # Iterating over all rows\n",
    "    for row in reader:\n",
    "        # Appending every data in all rows\n",
    "        data[\"LOTR\"].append({\"row\": row[0], \"characters\": row[1], \"dialogue\": row[2], \"movie\": row[3]})\n",
    "# Writing data to the json file\n",
    "with open(\"lotr_converted.json\", \"w\") as jsonFile:\n",
    "    json.dump(data, jsonFile, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nr. 1.2\n",
    "\n",
    "- Write a Python program `csv2json` to convert a given CSV file into a JSON file. This conversion should be generic as possible and able to convert different types of CSV files. For the beginning try to make it work with the [`lotr_clean.csv`](lotr_clean.csv) file I uploaded to GitHub. Think about the generic parts. Where do the JSON key names come from? What about different types of separators? Try to build your program from \"simple\" to \"a bit more complex\" and think about how to split the development within your group. Document your program and remember to commit early and commit often.\n",
    "\n",
    "Now comes the more difficult part. We try to rewrite our program in a way that in the best case every .csv file can be read and output as .json format. There are always exceptions but this should work for most cases. To format several files at once, we iterate through the entire working directory and search for the .csv files that we will use step by step. Of course we have to read in our file first. Here we come across our first bigger problem. In the first part of the task it was still clear which delimiter the .csv file uses, but to be able to accept different delimiters we use the `sniffer()` function. With this we can find out which delimiter the file uses by testing a sample. Our next problem are the column names. We cannot type them by hand like in the first part but have to search for them. Here the function `fieldnames` does the work for us. At this point we can simply use all the data we have collected as in the first part of the task.  \n",
    "So that the task is fulfilled the final program is also executable with the file [`csv2json.py`](./csv2json.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "print(\"Importing files...\")\n",
    "# Iterating over all files that end with \".csv\" in the current working directory\n",
    "for csvFilename in os.listdir(\".\"):\n",
    "    if not csvFilename.endswith(\".csv\"):\n",
    "        continue\n",
    "    print(\"Working...\")\n",
    "    # Opening the CSV file\n",
    "    with open(csvFilename, \"r\") as csvFile:\n",
    "        # Reading in a sample and testing which delimiter is used\n",
    "        dialect = csv.Sniffer().sniff(csvFile.read(1000), delimiters=\";,\")\n",
    "        csvFile.seek(0)\n",
    "        # Reading in the CSV file\n",
    "        reader = csv.DictReader(csvFile, delimiter = dialect.delimiter)\n",
    "        # Searching for column headings\n",
    "        column_names = reader.fieldnames\n",
    "        # Creating base for later writing\n",
    "        base = []\n",
    "        for row in reader:\n",
    "            base.extend([{column_names[i]:row[column_names[i]] for i in range(len(column_names))}])\n",
    "        # Creating a new file\n",
    "        with open(csvFilename + \"_converted_to.json\", \"w\") as jsonFile:\n",
    "            # Writing data to the JSON file\n",
    "            json.dump(base, jsonFile, indent=4)\n",
    "print(\"Done!\")\n",
    "input(\"Press any key to continue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "### Nr. 2.1\n",
    "\n",
    "- Your task is to transform a dataset on movies since 1950. Download the dataset [`movies.json`](movies.json) from our Github repository. Write a Python program to:\n",
    "\n",
    "  1. read in the data from the JSON file,\n",
    "  2. count for each year, how many movies per genre have appeared,\n",
    "  3. create a CSV file where for each year, the counts for each genre are listed.\n",
    "\n",
    "  Your final CSV should look something like this:\n",
    "\n",
    "year|Action|Adventure|Animation|...\n",
    "-----|------|----------|--------|---\n",
    "1950|39|42|65|...\n",
    "1951|...|...|...|...\n",
    "\n",
    "In this task we are dealing with a somewhat more difficult `.json` file. It is nested and therefore requires some more loops than in the other tasks. Opening and reading the file does not need to be explained again at this point. Similar to the first task, we made a list of all genres per year and put it in a dictionary.  \n",
    "To find out how often a genre appears in the movies per year, we counted this list of genres per year with the `Counter()` function. This function did a lot of the work for us.  \n",
    "We also created a list which contains all \"possible\" genres. We have sorted them to make it similar to the task example. Because some movies had no genres, we had to delete the first column of each entry.  \n",
    "The last step before writing the file is to prepare our \"base\" again. In this task this is called `dictio`. But so far it only contains the columns names and no dates or numbers. These are assigned to the respective columns only at the very end.  \n",
    "Finally we had to find a solution for the years in which a genre from another year does not occur. Therefore we set the value 0 for each genre not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import json\n",
    "import csv\n",
    "from collections import Counter\n",
    "# Opening the CSV file\n",
    "with open(\"./movies.json\", \"r\") as jsonfile:\n",
    "    # Reading in the CSV file\n",
    "    dataset = json.load(jsonfile)\n",
    "    # Creating function for better readability\n",
    "    def count_genre(year):\n",
    "        # Searching for all genres in all years and all films\n",
    "        genres = []\n",
    "        for films in dataset[year].keys():\n",
    "            genres.append(list(dataset[year][films][\"genre\"]))\n",
    "        genres = dict(Counter([y for x in genres for y in x]))\n",
    "        return(genres)\n",
    "    # Creating a list with all available genres\n",
    "    unique_genres = []\n",
    "    for x in dataset.keys():\n",
    "        for y in dataset[x].keys():\n",
    "            unique_genres.append(list(dataset[x][y][\"genre\"]))\n",
    "    sum_genres = [y for x in unique_genres for y in x]\n",
    "    # Sorting the list alphabetically and removing duples\n",
    "    sum_genres = sorted(list(dict.fromkeys(sum_genres)))\n",
    "    # Deleting the first row as there is no content (no genre)\n",
    "    del sum_genres[0]\n",
    "    # Creating a list with all years\n",
    "    years = []\n",
    "    years.append(list(dataset.keys()))\n",
    "    # Removing list in list\n",
    "    years = [y for x in years for y in x]\n",
    "    # Creating base for later writing\n",
    "    dictio = {}\n",
    "    for x in years:\n",
    "        dictio[x] = count_genre(x)\n",
    "    fieldnames = [\"year\"]\n",
    "    fieldnames.extend(sum_genres)\n",
    "# Creating a new file\n",
    "with open(\"./movies.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    # Writing data to the CSV file\n",
    "    writer = csv.writer(csvfile, delimiter=\",\")\n",
    "    writer.writerow(fieldnames)\n",
    "    for x in years:\n",
    "        numbers = [int(x)]\n",
    "        for y in sum_genres:\n",
    "            try:\n",
    "                numbers.append(dictio[x][y])\n",
    "            except KeyError:\n",
    "                numbers.append(0)\n",
    "        writer.writerow(numbers)"
   ]
  }
 ]
}